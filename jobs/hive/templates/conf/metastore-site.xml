<% 
  # Static values specific to hive
  db_driver = p('hive.db.driver')
  db_flags = p('hive.db.flags')

  # This is gross and I do not like it.
  db_host = nil
  if_p('hive.db.host') {|host| db_host = host}
  unless db_host
    db_host = link('postgres').instances.first.address
  end

  db_name = nil
  if_p('hive.db.name') {|name| db_name = name}
  unless db_name
    db_name = link('postgres').p('postgres.databases')[0]['name']
  end

  db_password = nil
  if_p('hive.db.password') {|password| db_password = password}
  unless db_password
    db_password = link('postgres').p('postgres.users')[0]['password']
  end

  db_port = nil
  if_p("hive.db.port") {|port| db_port = port}
  unless db_port
    db_port = link('postgres').p('postgres.config.port')
  end

  db_type = p('hive.db.type')

  db_username = nil
  if_p('hive.db.username') {|user| db_username = user}
  unless db_username
    db_username = link('postgres').p('postgres.users')[0]['username']
  end
  
 s3_access_key = nil
  if_p('s3.access_key') {|key| s3_access_key = key}
  unless s3_access_key
    if_link('minio') do |minio|
      s3_access_key = minio.p('credential.accesskey')
    end
  end

  s3_secret_key = nil
  if_p('s3.secret_key') {|key| s3_secret_key = key }
  unless s3_secret_key
    if_link('minio') do |minio|
      s3_secret_key = minio.p('credential.secretkey')
    end
  end

  s3_ssl_enabled = nil
  if_p('s3.ssl_enabled') {|ssl| s3_ssl_enabled = ssl }
  unless s3_ssl_enabled
    if_link('minio') do |minio|
      minio.if_p('server_cert') {s3_ssl_enabled = true}
    end
  end

  s3_port = nil
  if_p('s3.port') {|port| s3_port = port}
  unless s3_port
    if_link('minio') do |minio|
      s3_port = minio.p('port')
    end
  end

  s3_host = nil
  if_p('s3.host') {|host| s3_host = host}
  unless s3_host
    if_link('minio') {|minio| s3_host = minio.instances.first.address}
  end

  s3_endpoint = nil
  if_p('s3.endpoint') {|url| s3_endpoint = url}
  unless s3_endpoint
    protocol = "http"
    if s3_ssl_enabled == true
      protocol = "https"
    end
    s3_endpoint = "#{protocol}://#{s3_host}:#{s3_port}"
  end

  db_url = "jdbc:#{db_type}://#{db_host}:#{db_port}/#{db_name}#{db_flags}"
-%>
<configuration>
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value><%= db_url %>></value>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value><%= db_driver %></value>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value><%= db_username %></value>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value><%= db_password %></value>
  </property>
  <property>
    <name>hive.metastore.event.db.notification.api.auth</name>
    <value>false</value>
  </property>
  <property>
    <name>fs.s3a.access.key</name>
    <value><%= s3_access_key %></value>
  </property>
  <property>
    <name>fs.s3a.secret.key</name>
    <value><%= s3_secret_key %></value>
  </property>
  <property>
    <name>fs.s3a.connection.ssl.enabled</name>
    <value><%= s3_ssl_enabled %></value>
  </property>
  <property>
    <name>fs.s3a.path.style.access</name>
    <value>true</value>
  </property>
  <property>
    <name>fs.s3a.endpoint</name>
    <value><%= s3_endpoint %></value>
  </property>
  <property>
    <name>metastore.task.threads.always</name>
    <value>org.apache.hadoop.hive.metastore.events.EventCleanerTask</value>
  </property>
  <property>
    <name>metastore.expression.proxy</name>
    <value>org.apache.hadoop.hive.metastore.DefaultPartitionExpressionProxy</value>
  </property>
  <property>
    <name>metastore.warehouse.dir</name>
    <value>/var/vcap/store/hive/metastore</value>
  </property>
  <property>
    <name>metastore.log4j.file</name>
    <value>/var/vcap/jobs/hive/conf/metastore-log4j.properties</value>
  </property>
  <property>
    <name>hive.stats.autogather</name>
    <value>false</value>
  </property>
</configuration>